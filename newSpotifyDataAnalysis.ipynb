{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of Contents\n",
    "1. [Importing Libraries](#importing-libraries)\n",
    "2. [Data Description](#data-description)\n",
    "    * [Multiple Genres](#multiple-genres)\n",
    "3. [Data Preprocessing](#data-cleaning)\n",
    "4. [Data Modelling](#data-modelling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries <a class=\"anchor\" id=\"importing-libraries\"></a>\n",
    "\n",
    "Here, we import all the necessary libraries for our work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mnumpy\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mnp\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Description <a class=\"anchor\" id=\"data-description\"></a>\n",
    "\n",
    "First, the data is loaded and basic information about the data is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m tracks \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m'\u001b[39m\u001b[39mcsvs/dataset.csv\u001b[39m\u001b[39m'\u001b[39m, index_col\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m      3\u001b[0m tracks\u001b[39m.\u001b[39mhead()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "tracks = pd.read_csv('csvs/dataset.csv', index_col=0)\n",
    "\n",
    "tracks.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our goal is to identify and predict the genres of the song, so we try display and see how many genres are there in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Number of genres: {}'.format(tracks.track_genre.nunique()))\n",
    "\n",
    "# Get a count of all genre\n",
    "tracks.track_genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple Genres <a class=\"anchor\" id=\"multiple-genres\"></a>\n",
    " \n",
    "We discover that some song may have multiple genres. To improve our modelling, we will be using tracks with one genre only. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by popularity first, so when we drop duplicate we drop lower popularity\n",
    "# Drop duplicate if track_name, duration_ms, artists and track_genre are all the same\n",
    "tracks.sort_values(by=['popularity'],ascending=False,inplace=True)\n",
    "tracks.drop_duplicates(subset=['track_name','duration_ms','artists','track_genre'],inplace=True)\n",
    "\n",
    "# If track_name, duration_ms and artists are same, but genre is different, aggregate the genre\n",
    "tracks = tracks.groupby(['track_name','duration_ms','artists'],as_index=False).agg({'track_genre':lambda x: ','.join(x),\n",
    "                                                                                                  'album_name': 'first',\n",
    "                                                                                                  'track_id': 'first',\n",
    "                                                                                                  'popularity': 'max',\n",
    "                                                                                                  'explicit': 'first',\n",
    "                                                                                                  'danceability': 'first',\n",
    "                                                                                                  'energy': 'first',\n",
    "                                                                                                  'loudness': 'first',\n",
    "                                                                                                  'speechiness': 'first',\n",
    "                                                                                                  'acousticness': 'first',\n",
    "                                                                                                  'instrumentalness': 'first',\n",
    "                                                                                                  'liveness': 'first',\n",
    "                                                                                                  'valence': 'first',\n",
    "                                                                                                  'tempo': 'first',\n",
    "                                                                                                  'key': 'first',\n",
    "                                                                                                  'mode': 'first'})\n",
    "\n",
    "\n",
    "# Remove all tracks with more than one genre\n",
    "tracks = tracks[tracks['track_genre'].str.contains(',') == False]\n",
    "tracks.track_genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Additionally, any genre with less than 500 tracks does not constitute enough training and test sample, and will be removed from the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove all genres with less than 500 tracks, maintain all columns\n",
    "tracks = tracks.groupby('track_genre').filter(lambda x: len(x) > 500)\n",
    "tracks.track_genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing <a class=\"anchor\" id=\"data-cleaning\"></a>\n",
    "\n",
    "We start off with basic data cleaning, removing null data and removing unnecessary columns according to our EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the row where track_name = null\n",
    "tracks.drop(tracks.index[tracks['track_name'].isnull()], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make our modelling easier, we will limit our selection to a hand selected few genres. As much as the top 10 genre present an interesting opportunity, a cursory glance at the data shows that the top 10 genres are not very distinct from each other. Hence, we will select a few genres that are more significantly distinct from one another."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genre_popularity = tracks.groupby('track_genre')['popularity'].mean()\n",
    "genre_popularity.sort_values(ascending=False)\n",
    "\n",
    "# What is the difference between pop-film, k-pop, pop? \n",
    "# And what is the difference between sad and emo?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We choose the following genre for our modelling, and remove the rest of the genres from the dataset.\n",
    "- Country\n",
    "- Chill\n",
    "- K-Pop\n",
    "- Club\n",
    "- Rock-n-Roll\n",
    "- Classical\n",
    "- Sleep\n",
    "- Electronic\n",
    "- Ambient\n",
    "- Opera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retain only the genres listed above\n",
    "tracks = tracks[tracks['track_genre'].isin(['country', 'chill', 'k-pop', 'club', 'rock-n-roll', 'classical', 'sleep', 'electronic', 'ambient', 'opera'])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also remove Track ID from our dataset as the ID is randomly generated data. Additionally, track name, artist name and album name will be removed as well. These three category are too diverse and will be hard to generalize, even if they provide very useful information. \n",
    "\n",
    "We will also drop the track key, as it will present too many dimension for our model to handle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the track_id column\n",
    "tracks.drop('track_id', axis=1, inplace=True)\n",
    "\n",
    "# Drop the track_name, artists, album_name columns\n",
    "tracks.drop(['track_name', 'artists', 'album_name'], axis=1, inplace=True)\n",
    "\n",
    "# Drop the key column\n",
    "tracks.drop('key', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will discretize both loudness, tempo and duration_ms into 10 bins each. The exact value of these columns are not important, but their rough bins will help better inform the model.\n",
    "\n",
    "We will also normalise the popularity columns, as they are on a different scale from the rest of the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discretize the loudness column into 10 bins, normalised within 0 and 1\n",
    "tracks['loudness'] = pd.cut(tracks['loudness'], 10, labels=False)\n",
    "tracks['loudness'] = MinMaxScaler().fit_transform(tracks[['loudness']])\n",
    "\n",
    "# Discretize the tempo column into 10 bins, normalised within 0 and 1\n",
    "tracks['tempo'] = pd.cut(tracks['tempo'], 10, labels=False)\n",
    "tracks['tempo'] = MinMaxScaler().fit_transform(tracks[['tempo']])\n",
    "\n",
    "# Normalise the duration_ms column through the use of log transformation, then normalise within 0 and 1\n",
    "tracks['duration_ms'] = np.log(tracks['duration_ms'])\n",
    "tracks['duration_ms'] = MinMaxScaler().fit_transform(tracks[['duration_ms']])\n",
    "\n",
    "# Normalise the popularity column through MinMaxScaler\n",
    "tracks['popularity'] = MinMaxScaler().fit_transform(tracks[['popularity']])\n",
    "\n",
    "# Describe the dataset\n",
    "tracks.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we make sure each of the genres has 500 sample exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop individual rows until the number of tracks per genre is equal\n",
    "tracks = tracks.groupby('track_genre').apply(lambda x: x.sample(tracks.track_genre.value_counts().min(), random_state=42).reset_index(drop=True))\n",
    "tracks.track_genre.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save data<a class=\"anchor\" id=\"data-modelling\"></a>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "clean_dataset.to_csv('clean_data.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Modelling <a class=\"anchor\" id=\"data-modelling\"></a>\n",
    "\n",
    "Placeholder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train test split\n",
    "X = tracks.drop('track_genre', axis=1)\n",
    "y = tracks['track_genre']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n",
    "\n",
    "# Random Forest Classifier\n",
    "rfc = RandomForestClassifier(n_estimators=100)\n",
    "rfc.fit(X_train, y_train)\n",
    "rfc_pred = rfc.predict(X_test)\n",
    "\n",
    "print('Random Forest Classifier')\n",
    "print('Accuracy: {}'.format(accuracy_score(y_test, rfc_pred)))\n",
    "print('Confusion Matrix: \\n{}'.format(confusion_matrix(y_test, rfc_pred)))\n",
    "print('Classification Report: \\n{}'.format(classification_report(y_test, rfc_pred)))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
